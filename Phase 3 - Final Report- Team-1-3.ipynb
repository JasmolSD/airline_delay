{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8bac9eab-2bd8-4f6e-b0b2-9d473a8d5487",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Phase 3 Final Report\n",
    "DATASCI 261: Machine Learning at Scale\n",
    "Ahsin Saleem, Anshul Zutshi, Cat Weiss, Jasmol Dhesi, Umesh Kant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12b1af5b-0e59-4f1c-adde-6d505232411e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Team and Project Meta Information\n",
    "## Team 1_3\n",
    "\n",
    "## Team Members\n",
    "|<img src=\"https://cweiss10.github.io/261_images/images/team_members/Umesh_Profile_Pic2.png\" width=\"100\">| <img src=\"https://cweiss10.github.io/261_images/images/team_members/Professional%20Picture.JPG\" width=\"100\"> |\n",
    "|-------------------------|-------------------------|\n",
    "| **Umesh Kant**         | **Jasmol Dhesi**        |\n",
    "| umesh_kant@berkeley.edu | jasmol_dhesi@berkeley.edu |\n",
    "\n",
    "| <img src=\"https://cweiss10.github.io/261_images/images/team_members/anshul_zutshi_profile.png\" width=\"100\"> | <img src=\"https://cweiss10.github.io/261_images/images/team_members/IMG_5835_Small.png\" width=\"100\"> |\n",
    "|-------------------------|-------------------------|\n",
    "| **Anshul Zutshi**         | **Ahsin Saleem**        |\n",
    "| anshulzutshi@berkeley.edu | ahsin.saleem@berkeley.edu |\n",
    "\n",
    "| <img src=\"https://cweiss10.github.io/261_images/images/team_members/cw_picture.png\" width=\"100\">|\n",
    "|-------------------------|\n",
    "| **Cat Weiss**          |\n",
    "| catweiss@berkeley.edu  |\n",
    "<br>\n",
    "## Credit Assignment Plan by phases\n",
    "### Phase Leader Plan & Phase 1 Credit Assignment Plan\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td>\n",
    "      <h3>Phase Leader Plan</h3>\n",
    "      <table>\n",
    "        <tr>\n",
    "          <th>Phase</th>\n",
    "          <th>Leader(s)</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Phase One</td>\n",
    "          <td>Cat Weiss</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Phase Two</td>\n",
    "          <td>Umesh Kant, Jasmol Dhesi</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Phase Three</td>\n",
    "          <td>Ahsin Saleem, Anshul Zutshi</td>\n",
    "        </tr>\n",
    "      </table>\n",
    "    </td>\n",
    "    <td style=\"padding-left:50px;\">\n",
    "      <h3>Credit Assignment Plan for Phase 1</h3>\n",
    "      <table>\n",
    "        <tr>\n",
    "          <th>Task</th>\n",
    "          <th>Responsible Person(s)</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Abstract</td>\n",
    "          <td>Jasmol Dhesi</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Data Description</td>\n",
    "          <td>Umesh Kant, Cat Weiss</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Machine Learning Algorithms and Metrics</td>\n",
    "          <td>Ahsin Saleem</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Machine Learning Pipelines</td>\n",
    "          <td>Anshul Zutshi</td>\n",
    "        </tr>\n",
    "      </table>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "### Phase 2 Credit Assignment Plan\n",
    "<table>\n",
    "        <tr>\n",
    "          <th>Task</th>\n",
    "          <th>Responsible Person(s)</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Abstract</td>\n",
    "          <td>Cat Weiss</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Project Description</td>\n",
    "          <td>Anshul Zutshi</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>EDA</td>\n",
    "          <td>Umesh Kant and Anshul Zutshi</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Feature Engineering</td>\n",
    "          <td>Cat Weiss</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Baseline</td>\n",
    "          <td>Ahsin Saleem</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Advanced Models</td>\n",
    "          <td>Jasmol Dhesi and Ahsin Saleem</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Conclusion and Results</td>\n",
    "          <td>Jasmol Dhesi</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Extra Credit - Data Join</td>\n",
    "          <td>Umesh Kant</td>\n",
    "        </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "### Phase 3 Credit Assignment Plan\n",
    "<table>\n",
    "        <tr>\n",
    "          <th>Task</th>\n",
    "          <th>Responsible Person(s)</th>\n",
    "        </tr>\n",
    "          <td>EDA</td>\n",
    "          <td>Umesh Kant and Anshul Zutshi</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Feature Engineering</td>\n",
    "          <td>Cat Weiss and Anshul Zutshi</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>ML Based Pipeline</td>\n",
    "          <td>Ahsin Saleem</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Experimenting with features & Improvements</td>\n",
    "          <td>Jasmol Dhesi, Ahsin Saleem, Anshul Zutshi, and Umesh Kant</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "          <td>Data Join</td>\n",
    "          <td>Umesh Kant and Ahsin Saleem</td>\n",
    "        </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d41c1d1-2a78-4405-9dc1-97713327e7b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Project Abstract\n",
    "We built a predictive model to determine whether a flight will be delayed by 15 minutes or more, using historical flight data, flight attributes, and weather conditions. The primary goal is to help passengers and airline stakeholders anticipate delays and make proactive travel decisions.\n",
    "\n",
    "While multiple performance metrics like f1-score, precision, accuracy, and ROC score were considered, recall was prioritized as the key measure of success—reflecting our focus on minimizing missed delay predictions. We wanted to prioritize a model that minimized false negatives or unexpected delays to alert customers and help them keep up with flight delays.  We experimented with a range of models, from a simple random choice baseline to more complex classifiers, including logistic regression, random forests, and multi-layer perceptrons (MLPs).\n",
    "\n",
    "Among all models, the MLP with a single hidden layer achieved the highest recall (0.2879), outperforming logistic regression (0.1676) and random forests (0.097). Though logistic regression had the highest AUC and precision, its relatively low recall made it less suitable for our goal. The absolute baseline, which randomly predicts classes based on the training data class distribution, performed poorly across all metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a553d70-4faf-48e5-804f-5bb4494c6c54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Description\n",
    "\n",
    "Our datasets come from the [TranStats data collection available from the US Department of transportation](https://www.transtats.bts.gov/Fields.asp?gnoyr_VQ=FGJ) for on time and delay flight information, and from the [National Oceanic and Atmospheric Administration Repository](https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.ncdc:C00679) for weather data. They have been joined together in one table which has been provided to us as the On time performance of flights and weather (OTPW) dataset. We performed EDA analysis on 60-month data subset of training data for the joined dataset (OTPW) which contains flights performance, airport codes and weather datasets.\n",
    "\n",
    "We considered a flight \"delayed\" if it arrived at least 15 minutes later than its scheduled arrival time. We decided on 15 minutes as our threshold after much internal debate and external research. [This report](https://aspm.faa.gov/aspmhelp/index/Types_of_Delay.html) from the Federal Aviation Administration states they do not report delays of less than 15 minutes and OAG, a leading provider of digital flight information also defines a flight delay to be of at least 15 minutes and discusses establishing the threshold in more depth [in this article](https://www.oag.com/airline-on-time-performance-defining-late)\n",
    "\n",
    "### Data Files\n",
    "For 60 months OTPW (On time performance of flights and weather), Following are the data file formats:\n",
    "- OTPW : Multiple Gunzipped CSV files of sizes in the range of 1.1 GB to 1.5 GB approximately\n",
    "\n",
    "Because our focus is classifying the delay of flights, we will use a subset of the relevant columns in the table for our project which are detailed in the EDA section.\n",
    "\n",
    "## Project Plan\n",
    "After performing initial exploratory data analysis (EDA) on the various datasets in phase 2, we began cleaning and preprocessing the OTPW (On-Time Performance and Weather) dataset to format the data in a way that is easily digestible by machine learning models.\n",
    "\n",
    "The data cleaning process began with removing duplicate rows and handling missing values across columns. We then performed feature engineering, which included—but was not limited to—type conversion for numerical and categorical variables, one-hot encoding of categorical features, combining relevant columns, and generating new features such as time-based features and holiday boolean field.\n",
    "\n",
    "To improve model performance and efficiency, we conducted dimensionality reduction and feature analysis using correlation matrices and domain knowledge to reduce noise and eliminate redundant or uninformative features.\n",
    "\n",
    "We started with a simple baseline model that randomly predicted flight delays based on class distribution (~79% on-time, ~21% delayed), establishing a benchmark for our future models. This was followed by a baseline logistic regression model trained on the cleaned and engineered dataset. We evaluated its performance with precision selected as our top-line metric and recall and AUC as supplemental metrics.\n",
    "\n",
    "We chose precision as our main evaluation metric because in a real-world deployment scenario, a false positive (predicting a flight will be delayed when it's actually on time) could lead to unnecessary operational interventions or miscommunication to passengers leading to missed flights. By focusing on precision, we aim to ensure that when our model predicts a delay, it's doing so with high confidence and minimal false alarms.\n",
    "\n",
    "In 3rd and Final Phase, we focussed on:\n",
    "- Experiment more with feature selection\n",
    "- Tune and experiment with additional classifiers (e.g., Random Forest, and Neural Networks).\n",
    "- Finalize the pipeline which is foundational for a robust and interpretable flight delay prediction system grounded in precision-focused decision-making.\n",
    "\n",
    "## EDA\n",
    "## 60 months OTPW\n",
    "Joined dataset (OTPW) which contains flights performance, airport codes and weather datasets for 60 months, which has 31,673,119 rows, and 214 attributes.\n",
    "### Data Dictionary of Key Features Used by Models\n",
    "|Feature Name|Description|\n",
    "|---|---|\n",
    "|YEAR|Year (int)|\n",
    "|QUARTER|Quarter (1-4) (int)|\n",
    "|MONTH|Month (int)|\n",
    "|DAY_OF_MONTH|Day of Month (int)|\n",
    "|DAY_OF_WEEK|Day of Week (int)|\n",
    "|OP_UNIQUE_CARRIER|Unique Carrier Code. When the same code has been used by multiple carriers, a numeric suffix is used for earlier users, for example, PA, PA(1), PA(2). Use this field for  across a range of years. (String)|\n",
    "|CRS_DEP_TIME|CRS Departure Time (local time: hhmm) (int)|\n",
    "|CRS_ARR_TIME|CRS Arrival Time (local time: hhmm) (int)|\n",
    "|SCHED_DEPART_UNIX|Scheduled Departure Time in Unix epoch (long)|\n",
    "|CRS_ELAPSED_TIME|CRS Elapsed Time of Flight, in Minutes (double)|\n",
    "|DISTANCE|Distance between airports (miles) (double)|\n",
    "|ORIGIN_TYPE|Origin Airport Type (string)|\n",
    "|ORIGIN_AIRPORT_LAT|Origin Airport Latitude (double)|\n",
    "|ORIGIN_AIRPORT_LON|Origin Airport Longitude (double)|\n",
    "|DEST_TYPE|Destination Airport Type (string)|\n",
    "|DEST_AIRPORT_LAT|Destination Airport Latitude (double)|\n",
    "|DEST_AIRPORT_LON|Destination Airport Longitude (double)|\n",
    "|ELEVATION|Airport Elevation (double)|\n",
    "|HourlyAltimeterSetting|Hourly Altimeter Setting (float)|\n",
    "|HourlyDewPointTemperature|Hourly Dew Point Temperature (float)|\n",
    "|HourlyDryBulbTemperature|Hourly Dry Bulb Temperature (float)|\n",
    "|HourlyPrecipitation|Hourly Precipitation (float)|\n",
    "|HourlyRelativeHumidity|Hourly Relative Humidity (float)|\n",
    "|HourlyStationPressure|Hourly Station Pressure (float)|\n",
    "|HourlyVisibility|Hourly Visibility (float)|\n",
    "|HourlyWetBulbTemperature|Hourly Wet Bulb Temperature (float)|\n",
    "|HourlyWindSpeed|Hourly Wind Speed (float)|\n",
    "|HAS_WEATHER_TYPE|Has Weather Type (1=Yes, 0=No) (int)|\n",
    "|IS_HOLIDAY|Within 3 days of a US Holiday (1=Yes, 0=No) (string)|\n",
    "|rolling_3mo_delay_count|Rolling 3 Month Delay Count By Airline (long)|\n",
    "\n",
    "### Key Data Exploration Observations\n",
    "**Cancelled Flights**: 1.5 percent of the flights were cancelled. <br>\n",
    "**Diverted Flights**: 0.2 percent of the flights were diverted. <br>\n",
    "**Delayed Flights**: 34.4 percent of the flights were delayed. <br>\n",
    "**Causes of Delay**: <br>\n",
    "Following are the key causes for flight delays:<br>\n",
    "- Carrier Delay\n",
    "- Weather Delay\n",
    "- National Air System Delay\n",
    "- Security Delay\n",
    "- Late Aircraft Delay\n",
    "![](https://cweiss10.github.io/261_images/images/final_causes_of_delay.png) <br>\n",
    "Late aircraft delay is the top cause for arrival delay in minutes overall and security delay is the bottom cause for arrival delay in minutes overall.<br>\n",
    "**Arrival Delay Distribution** <br>\n",
    "Histograms below show the distribution of Flight delay (Arrival Delay) based on 60 months of OTPW data. Using log scale option in Databricks visualization on X axis, helps with better readability of different delay bins. As we can see a lot of flights arrive on or before time in comparison to delayed flights.<br>\n",
    "![](https://cweiss10.github.io/261_images/images/final_arr_delay_histogram.png) <br>\n",
    "The histogram on the top is hard to read due to high concentration of flights performance data between 25 minutes early to 50 minutes late range. The Databricks Visualization offers an option of choosing log scale which zooms in well on the range of 100 minutes early to 200 minutes late arrival and somehow also handles the negative values as well corresponding to early arrivals, even though log of negative values is not defined.<br>\n",
    "**Weather Conditions** <br>\n",
    "Focussing on all the flights that had weather related delays, looking into following visualizations individually does not offer much clue due to wide range of values for each weather condition.\n",
    "![](https://cweiss10.github.io/261_images/images/final_avg_hourly_visibility.png) <br>\n",
    "![](https://cweiss10.github.io/261_images/images/final_avg_hourly_station_pressure.png) <br>\n",
    "![](https://cweiss10.github.io/261_images/images/final_avg_hourly_precipitation.png) <br>\n",
    "The models will learn the combination of these weather conditions that lead to flight delays.\n",
    "## Airline On-Time Performance Data (Flights)\n",
    "A subset of passenger flight's on-time performance data taken from US department of Transportation.<br>\n",
    "**Time Duration**: 2015 to 2021<br>\n",
    "**Dimensions**: 74,177,433 rows, 109 features<br>\n",
    "### **Data Dictionary**:<br>\n",
    "**Time Period**:<br>\n",
    "<img src=\"https://cweiss10.github.io/261_images/images/flights_DD_timePeriod.png\"><br>\n",
    "**Carrier**:<br>\n",
    "<img src=\"https://cweiss10.github.io/261_images/images/flights_DD_carrier.png\"><br>\n",
    "**Origin**:<br>\n",
    "<img src=\"https://cweiss10.github.io/261_images/images/flights_DD_origin.png\"><br>\n",
    "**Destination**:<br>\n",
    "<img src=\"https://cweiss10.github.io/261_images/images/flights_DD_destination.png\"><br>\n",
    "**Departure Performance**:<br>\n",
    "<img src=\"https://cweiss10.github.io/261_images/images/flights_DD_departure_performance.png\"><br>\n",
    "**Arrival Performance**:<br>\n",
    "<img src=\"https://cweiss10.github.io/261_images/images/flights_DD_arrival_performance.png\"><br>\n",
    "**Cancellations & Diversions**:<br>\n",
    "<img src=\"https://cweiss10.github.io/261_images/images/flights_DD_cancellations_diversions.png\"><br>\n",
    "**Flights Summary**:<br>\n",
    "<img src=\"https://cweiss10.github.io/261_images/images/flights_DD_summary.png\"><br>\n",
    "**Delay Causes**:<br>\n",
    "<img src=\"https://cweiss10.github.io/261_images/images/flights_DD_delay_causes.png\"><br>\n",
    "**Gate Return at Origin Airport**:<br>\n",
    "<img src=\"https://cweiss10.github.io/261_images/images/flights_DD_gateReturn_at_origin.png\"><br>\n",
    "**Diverted Airport Flight Information**:<br>\n",
    "<img src=\"https://cweiss10.github.io/261_images/images/flights_DD_diverted_airport_info.png\"><br>\n",
    "\n",
    "## Weather\n",
    "The table contains weather records from multiple stations, with both hourly and daily metrics. It includes measurements of temperature, humidity, wind speed, precipitation, and pressure, along with metadata such as station id and report type. We performed an EDA analysis of a 3-month segment of the weather dataset, with its findings below.\n",
    "\n",
    "**Dimensions**: 30528602 rows, 124 features\n",
    "\n",
    "**Weather Dictionary**:<br>\n",
    "<img src=\"https://cweiss10.github.io/261_images/images/weather_dictionary.png\"><br>\n",
    "\n",
    "This is a dictionary detailing the key features in the weather dataset.<br>\n",
    "\n",
    "## Weather Stations\n",
    "The table contains stations records from stations with neighbor stations. It provides the station location through latitude and longtitude and the neighbor's id, name, location, and distance between the stations. We performed an EDA analysis of a 3-month segment of the weather stations dataset, with its findings below.\n",
    "\n",
    "**Dimensions**: 5004169 rows, 12 features\n",
    "\n",
    "**Weather Station Dictionary**:<br>\n",
    "<img src=\"https://cweiss10.github.io/261_images/images/weather_station_dictionary.png\"><br>\n",
    "\n",
    "This is a dictionary detailing the key features in the weather stations dataset. <br>\n",
    "\n",
    "## Airport codes data\n",
    "**Total distinct rows in the dataset**: 82,797 <br>\n",
    "**Total Distinct Countries**: 246 <br>\n",
    "**Total Distinct Regions** in US: 51 <br>\n",
    "<img src=\"https://cweiss10.github.io/261_images/images/airport_codes_map_large_airport.png\"><br>\n",
    "Above MAP view shows the large airports from the airports code dataset.<br>\n",
    "**Types of Airport**: <br>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Airport Type</th>\n",
    "    <th>Count</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>large_airport</td>\n",
    "    <td>482</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>medium_airport</td>\n",
    "    <td>4,684</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>small_airport</td>\n",
    "    <td>42,109</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>closed</td>\n",
    "    <td>12,472</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>seaplane_base</td>\n",
    "    <td>1,221</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>heliport</td>\n",
    "    <td>21,772</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>balloonport</td>\n",
    "    <td>57</td>\n",
    "  </tr>\n",
    "</table><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51aa8ca7-c91a-4286-91d0-e96545becc3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Our target variable for prediction is `DELAY_TARGET`, defined according to the FAA's threshold for delay — any arrival delayed by more than 15 minutes. This includes diverted and cancelled flights.\n",
    "\n",
    "### Derived Features\n",
    "\n",
    "Several engineered features were added to improve the model’s ability to capture temporal and environmental patterns:\n",
    "\n",
    "- **`IS_HOLIDAY`**: Boolean flag indicating whether the flight occurs within three days of a U.S. federal holiday.\n",
    "- **`rolling_3mo_delay_count`**: Time based feature: rolling count of delayed flights for the operating airline within the previous three months.\n",
    "- **`HAS_WEATHER_TYPE`**: Boolean indicating whether weather conditions causing visibility obstruction were present.\n",
    "\n",
    "### Weather Features\n",
    "\n",
    "Weather-related features were included where available and cleaned for consistency:\n",
    "- All numerical weather data (e.g., precipitation, temperature, wind speed, visibility) was converted to float.\n",
    "- Trace values were standardized to zero.\n",
    "- Suspect or missing values were reviewed and handled appropriately.\n",
    "\n",
    "\n",
    "### Correlation Analysis\n",
    "\n",
    "## Feature Correlation with Target Variable\n",
    "\n",
    "To understand the individual predictive power of our features, we computed the Pearson correlation between each feature and the target variable, `DELAY_TARGET` (1 if delayed or cancelled, 0 otherwise).\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "#### Top Positively Correlated Features:\n",
    "| Feature                  | Correlation |\n",
    "|--------------------------|-------------|\n",
    "| `HAS_WEATHER_TYPE`       | 0.089       |\n",
    "| `HourlyRelativeHumidity` | 0.084       |\n",
    "| `HourlyPrecipitation`    | 0.060       |\n",
    "| `HourlyWindSpeed`        | 0.038       |\n",
    "| `OP_UNIQUE_CARRIER`      | 0.031       |\n",
    "| `HourlyDewPointTemperature` | 0.019     |\n",
    "| `HourlyWindDirection`    | 0.017       |\n",
    "| `rolling_3mo_delay_count`| 0.016       |\n",
    "\n",
    "These features, especially weather-related ones, show mild positive correlations with flight delays. `HAS_WEATHER_TYPE`, indicating poor visibility conditions, is the most correlated feature.\n",
    "\n",
    "#### Top Negatively Correlated Features:\n",
    "| Feature                   | Correlation |\n",
    "|---------------------------|-------------|\n",
    "| `HourlyVisibility`        | -0.081      |\n",
    "| `HourlyAltimeterSetting`  | -0.065      |\n",
    "| `MONTH`                   | -0.034      |\n",
    "| `DAY_OF_WEEK`             | -0.034      |\n",
    "| `HourlyDryBulbTemperature`| -0.029      |\n",
    "| `YEAR`                    | -0.019      |\n",
    "| `origin_type`             | -0.016      |\n",
    "\n",
    "These inverse correlations suggest that better visibility, higher barometric pressure, and specific calendar periods may be associated with lower likelihood of delays. Below is the visualization of the feature correlation:\n",
    "\n",
    "![](https://cweiss10.github.io/261_images/images/feature_correlation.png)\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "None of the features are strongly correlated with the target (all under ±0.09), which is common in real-world classification problems where multiple factors interact. However, this correlation matrix still helped:\n",
    "- Validate our inclusion of weather-based features.\n",
    "- Confirm calendar-based seasonality.\n",
    "- Identify features with low or no correlation that may be pruned later in modeling.\n",
    "\n",
    "### Final Feature Set\n",
    "\n",
    "The final dataset includes 82 features. Categorical variables were one-hot encoded, while numeric and temporal variables were kept in ordinal form when appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4699ab2b-cfb6-418c-b925-427c929ae0f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Leakage Investigation\n",
    "\n",
    "### What is Data Leakage?\n",
    "\n",
    "**Data leakage** occurs when information from outside the training dataset — typically from the future — is used to create the model. This leads to overly optimistic performance estimates and poor real-world generalization because the model is inadvertently \"cheating\" by learning from data it wouldn't have access to in production.\n",
    "\n",
    "**Hypothetical example:**  \n",
    "Imagine predicting whether a customer will default on a loan, and including a feature like \"Was the loan written off?\" — a piece of information only known *after* the customer defaults. Including this would make the model highly accurate during training but useless in practice.\n",
    "\n",
    "\n",
    "### Leakage in Our Dataset\n",
    "\n",
    "After our Phase 2 presentation, we conducted a thorough investigation into potential sources of leakage in our data. We identified the following three variables as problematic:\n",
    "\n",
    "- `DEP_TIME` (Actual Departure Time)  \n",
    "- `DEP_DELAY` (Departure Delay in Minutes)  \n",
    "- `AIR_TIME` (Flight Duration)\n",
    "\n",
    "All three of these are only known *after* the flight has taken off. Since our goal is to predict whether a flight will be delayed **before takeoff**, these variables would not be available in a real-world deployment setting.\n",
    "\n",
    "Including them would introduce **target leakage**, as the model would be indirectly accessing future information to predict delays. As a result, we removed them from our feature set.\n",
    "\n",
    "\n",
    "### Final Pipeline Integrity\n",
    "\n",
    "With these variables removed, our final pipeline is free from data leakage. All features used by the model are strictly limited to data available **prior to scheduled departure**. This ensures that:\n",
    "\n",
    "- The model does not rely on information from the future\n",
    "- Model performance metrics are valid and trustworthy\n",
    "\n",
    "###Note:\n",
    "After the Phase 3 presentation, and following the professor’s advice, we conducted a deeper investigation into potential data leakage. We discovered that the “three-month flight delay count” feature unintentionally included the current month, which meant the model was gaining access to future information during training. This leakage inflated performance metrics by allowing the model to “peek” ahead. We have since corrected this by ensuring the feature only aggregates data from the three months prior to the prediction month, preserving the integrity of our time-based forecasting setup. The model performance dropped signifcantly after fixing this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3a4ef3e-1561-4f8d-81b2-8060d27f3515",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Absolute Baseline:\n",
    "\n",
    "Results:\n",
    "Precision = 0.2\n",
    "Recall = 0.2\n",
    "AUC = 0.5\n",
    "F1 Score = 0.5\n",
    "\n",
    "\n",
    "The baseline model makes predictions purely based on the class distribution in the data, without using any input features or training. Specifically, it predicts a flight will be \"on time\" (label 0) with a probability equal to the proportion of on-time flights in the dataset, and \"delayed\" (label 1) otherwise. This naive probabilistic approach results in poor performance, with a precision and recall of 0.2, indicating that only 20% of predicted delays were correct and only 20% of actual delays were identified. The AUC of 0.5 confirms the model's inability to distinguish between the two classes, performing no better than random guessing. While ineffective for real prediction, this baseline establishes the minimum threshold any meaningful model should surpass to demonstrate value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3877aaa1-3ce5-48d8-a968-3a3a513ca90b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Downsampling:\n",
    "\n",
    "To address class imbalance, we apply downsampling by retaining all delayed flights (the minority class, labeled as 1) and randomly sampling an equal number of on-time flights (the majority class, labeled as 0). This creates a balanced dataset where both classes are equally represented. To preserve the integrity of any time-dependent patterns in the data, the temporal order of the samples is maintained after combining the two classes. This strategy helps prevent the model from being biased toward the majority class while preserving the chronological structure important for time-based prediction tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "870dc1b3-f125-476b-9abc-6291c2ca0898",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Modeling Pipelines\n",
    "![](https://cweiss10.github.io/261_images/images/final_model_pipeline.png)\n",
    "\n",
    "###Modeling Pipeline Overview\n",
    "To prepare our dataset for training our models, we built a multi-step pipeline that transforms raw data into a format suitable for machine learning. Here's how it works:\n",
    "\n",
    "\n",
    "\n",
    "1. **Handle Categorical Variables:**\n",
    "\n",
    "    We began by identifying the columns in our data that are categorical in nature (e.g., origin airport, day of the week, carrier code). Since machine learning models can't work with text directly, we:\n",
    "    - Indexed each categorical variable using StringIndexer, converting text values into numeric codes.\n",
    "    - One-Hot Encoded the indexed columns using OneHotEncoder, turning each category into its own binary column. This avoids introducing any ordinal relationship between categories and keeps the model from misinterpreting them. (Skipped One hot encoding for Random Forest/MLP)\n",
    "2. **Prepare Numerical Features**\n",
    "\n",
    "    We selected a set of numerical columns, such as departure time, delay durations, flight distances, and weather measurements. These were included directly into the feature set.\n",
    "3. **Combine All Features**\n",
    "\n",
    "    After transforming the categorical and numerical features, we used VectorAssembler to combine all of them into a single feature vector called \"assembled_features\".\n",
    "4. **Normalize the Feature Values**\n",
    "\n",
    "    To ensure that all features contribute equally to the model (especially since they are on different scales), we applied MinMaxScaler. This scaled all feature values to a common range (typically 0 to 1), resulting in the \"scaled_features\" column.\n",
    "\n",
    "### 1. Baseline Model (Logistic Regression):\n",
    "- **Shape of feature matrix:** (2223856, 81)\n",
    "\n",
    "- **Loss Function**:\n",
    "    - The data loss (or log-likelihood) for logistic regression is given by:\n",
    "    $$\n",
    "\\ell(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m} \\left[\n",
    "   y_i \\log(\\hat{p}_i) + (1 - y_i) \\log(1 - \\hat{p}_i)\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "- **Cluster Size and Model Build Time:**\n",
    "The model training and evaluation were performed using 1 driver node and upto 10 scalable worker nodes. On average, it took approximately six minutes to train the logistic regression model end-to-end, including data preprocessing, feature transformation, and model fitting.\n",
    "\n",
    "#### 2 Random Forest Classifier\n",
    "- **Shape of feature matrix:** (2223856, 31)\n",
    "\n",
    "- **PySpark Class**: `pyspark.ml.classification.RandomForestClassifier`\n",
    "- **Description**:\n",
    "  - An **ensemble** of decision trees, each trained on a **bootstrapped** sample.\n",
    "  - Predictions are aggregated via **majority vote**.\n",
    "- **Objective**:\n",
    "  - Same node-splitting criteria (Gini) as a single decision tree, but across multiple trees.\n",
    "\n",
    "- **Cluster Size and Model Build Time:**\n",
    "The model training and evaluation were performed using 1 driver node and upto 10 scalable worker nodes. On average, it took approximately 60 minutes to train and grid search the best parameters for the Random Forest model end-to-end, including data preprocessing, feature transformation, and model fitting.\n",
    "\n",
    "#### 3 Multilayer Perceptron Classifier (Neural Network)\n",
    "- **Shape of feature matrix:** (2223856, 31)\n",
    "\n",
    "- **PySpark Class**: `pyspark.ml.classification.MultilayerPerceptronClassifier`\n",
    "- **Architecture**:\n",
    "  - Specify `layers` (e.g., `[numFeatures, hiddenUnits..., numClasses]`).\n",
    "- **Loss Function**:\n",
    "  - **Binary Cross-Entropy Loss.** with a **sigmoid** output layer for the binary classes.\n",
    "$$\n",
    "\\ell(\\theta) = - \\frac{1}{m} \\sum_{i=1}^{m} \\left[\n",
    "   y_i \\log(\\hat{p}_i) + (1 - y_i) \\log(1 - \\hat{p}_i)\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "- **Cluster Size and Model Build Time:**\n",
    "The model training and evaluation were performed using 1 driver node and upto 10 scalable worker nodes. On average, it took approximately 70 minutes to train and grid search the best parameters for the MLP model end-to-end, including data preprocessing, feature transformation, and model fitting.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "##Explanation of Metrics:\n",
    "\n",
    "**Precision, Recall, and AUC**\n",
    "\n",
    "  - **Precision**: The precision metric measures the proportion of true positive predictions among all positive predictions made by the model:\n",
    "  \n",
    "  $$\n",
    "  \\text{Precision} \\=\\frac{TP}{TP + FP}.\n",
    "  $$\n",
    "  - **Recall**: Also known as sensitivity or true positive rate, measures how well the model identifies positive instances:\n",
    "  $$\n",
    "  \\text{Recall} \\=\\frac{TP}{TP + FN}.\n",
    "  $$\n",
    "  - The F1 score is the harmonic mean of precision and recall:\n",
    "  $$\n",
    "  \\text{F1} \\=2*\\frac{Precision * Recall}{Precision + Recall}.\n",
    "  $$\n",
    "  - **AUC (Area Under the Curve)**:  AUC measures the ability of the model to discriminate between the positive and negative classes. It is the area under the ROC curve and ranges from 0 to 1, where a higher AUC represents better model performance.\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ef58807-c2ef-4a0b-a6aa-27ab0c44544a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Calibration Formula\n",
    "Calibration is applied to adjust the predicted probabilities from a model trained on a downsampled (i.e., artificially balanced) dataset, so they reflect the true likelihood of a positive outcome in the original, imbalanced data. This involves updating the posterior probability of a positive class using Bayes’ Rule, which incorporates the model’s predicted probability (derived from the rebalanced data) and the true class priors from the original distribution. By correcting for the mismatch in priors, calibration ensures that the output probabilities are properly scaled and interpretable as true likelihoods, which is especially important for threshold-based decision-making and evaluation metrics.\n",
    "\n",
    "$$\n",
    "\\frac{\n",
    "    \\text{PredictedProb} \\times \\left( \\frac{\\text{TruePosRate}}{\\text{SampledPosRate}} \\right)\n",
    "}{\n",
    "    \\text{PredictedProb} \\times \\left( \\frac{\\text{TruePosRate}}{\\text{SampledPosRate}} \\right)\n",
    "    +\n",
    "    (1 - \\text{PredictedProb}) \\times \\left( \\frac{1 - \\text{TruePosRate}}{1 - \\text{SampledPosRate}} \\right)\n",
    "}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ebfc3fb-d9e7-4053-b13b-c9f4001706c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Experimentation and Grid Search\n",
    "Here’s a **detailed experiment table** for **MLP (single/double layer)** and **Random Forest** with **all parameters tested** and their **average cross-validation results**:\n",
    "\n",
    "---\n",
    "\n",
    "### **MLP Single-Layer (1 Hidden Layer)**\n",
    "| **Param Set** | **Layers**    | **MaxIter** | **StepSize** | **Avg Precision** | **Avg Recall** | **Avg AUC** | **Avg F1** | **Calibrated Precision** | **Calibrated Recall** | **Calibrated AUC** | **Calibrated F1** |\n",
    "|---------------|---------------|-------------|--------------|-------------------|----------------|-------------|------------|---------------------------|------------------------|---------------------|--------------------|\n",
    "| 1/18          | [31, 10, 2]   | 25          | 0.01         | 0.6009            | 0.5617         | 0.6354      | 0.5805     | 0.6807                   | 0.1813                | 0.6365             | 0.2862            |\n",
    "| 2/18          | [31, 10, 2]   | 25          | 0.05         | 0.5997            | 0.5783         | 0.6369      | 0.5883     | 0.6801                   | 0.1923                | 0.6379             | 0.2995            |\n",
    "| 3/18          | [31, 10, 2]   | 50          | 0.01         | 0.6179            | 0.4603         | 0.6354      | 0.5077     | 0.6929                   | 0.1633                | 0.6356             | 0.2483            |\n",
    "| 4/18          | [31, 10, 2]   | 50          | 0.05         | 0.6062            | 0.5163         | 0.6359      | 0.5506     | 0.6904                   | 0.1620                | 0.6355             | 0.2553            |\n",
    "| 5/18          | [31, 10, 2]   | 100         | 0.01         | 0.5964            | 0.5941         | 0.6381      | 0.5947     | 0.6650                   | 0.2727                | 0.6389             | 0.3866            |\n",
    "| 6/18          | [31, 10, 2]   | 100         | 0.05         | 0.5789            | **0.7003**     | **0.6412**  | **0.6292** | 0.6537                   | **0.3818**            | **0.6435**         | **0.4653**        |\n",
    "| 7/18          | [31, 20, 2]   | 25          | 0.01         | 0.6074            | 0.5351         | 0.6377      | 0.5670     | 0.6881                   | 0.1679                | 0.6368             | 0.2666            |\n",
    "| 8/18          | [31, 20, 2]   | 25          | 0.05         | 0.6063            | 0.5350         | 0.6367      | 0.5680     | 0.6858                   | 0.1655                | 0.6358             | 0.2661            |\n",
    "| 9/18          | [31, 20, 2]   | 50          | 0.01         | 0.6139            | 0.5110         | 0.6395      | 0.5519     | 0.6904                   | 0.1825                | 0.6380             | 0.2768            |\n",
    "| 10/18         | [31, 20, 2]   | 50          | 0.05         | 0.6129            | 0.5198         | 0.6393      | 0.5548     | 0.6943                   | 0.1788                | 0.6394             | 0.2712            |\n",
    "| 11/18         | [31, 20, 2]   | 100         | 0.01         | 0.5821            | 0.6766         | 0.6390      | 0.6256     | 0.6560                   | 0.3539                | 0.6425             | 0.4562            |\n",
    "| 12/18         | [31, 20, 2]   | 100         | 0.05         | 0.5761            | 0.7055         | 0.6393      | 0.6321     | 0.6529                   | 0.3761                | 0.6431             | 0.4622            |\n",
    "| 13/18         | [31, 30, 2]   | 25          | 0.01         | 0.6066            | 0.5432         | 0.6353      | 0.5721     | 0.6828                   | 0.1870                | 0.6365             | 0.2919            |\n",
    "| 14/18         | [31, 30, 2]   | 25          | 0.05         | 0.6127            | 0.5122         | 0.6355      | 0.5573     | 0.6882                   | 0.1717                | 0.6369             | 0.2737            |\n",
    "| 15/18         | [31, 30, 2]   | 50          | 0.01         | 0.6166            | 0.4881         | 0.6343      | 0.5379     | 0.6911                   | 0.1791                | 0.6370             | 0.2727            |\n",
    "| 16/18         | [31, 30, 2]   | 50          | 0.05         | 0.6048            | 0.5542         | 0.6355      | 0.5758     | 0.6804                   | 0.2199                | 0.6378             | 0.3244            |\n",
    "| 17/18         | [31, 30, 2]   | 100         | 0.01         | 0.6077            | 0.5769         | **0.6430**  | 0.5914     | 0.6928                   | 0.2315                | **0.6466**         | 0.3470            |\n",
    "| 18/18         | [31, 30, 2]   | 100         | 0.05         | 0.5902            | 0.6569         | 0.6412      | 0.6209     | 0.6752                   | 0.2941                | 0.6468             | 0.4095            |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **MLP Double-Layer (2 Hidden Layers)**\n",
    "| **Param Set** | **Layers**         | **MaxIter** | **StepSize** | **Avg Precision** | **Avg Recall** | **Avg AUC** | **Avg F1** | **Calibrated Precision** | **Calibrated Recall** | **Calibrated AUC** | **Calibrated F1** |\n",
    "|---------------|--------------------|-------------|--------------|-------------------|----------------|-------------|------------|---------------------------|------------------------|---------------------|--------------------|\n",
    "| 1/12          | [31, 20, 10, 2]   | 50          | 0.01         | 0.6230            | 0.4449         | 0.6348      | 0.5083     | 0.7014                   | 0.1345                | 0.6364             | 0.2180            |\n",
    "| 2/12          | [31, 20, 10, 2]   | 50          | 0.03         | 0.6129            | 0.5231         | 0.6412      | 0.5639     | 0.6959                   | 0.2077                | 0.6412             | 0.3188            |\n",
    "| 3/12          | [31, 20, 10, 2]   | 100         | 0.01         | 0.5960            | **0.6050**     | **0.6424**  | **0.5998** | 0.6642                   | **0.3275**            | **0.6422**         | **0.4354**        |\n",
    "| 4/12          | [31, 20, 10, 2]   | 100         | 0.03         | **0.5922**        | 0.6330         | **0.6435**  | 0.6115     | **0.6675**               | 0.3276                | **0.6440**         | **0.4355**        |\n",
    "| 5/12          | [31, 30, 15, 2]   | 50          | 0.01         | 0.5465            | 0.5278         | 0.5545      | 0.5366     | 0.3454                   | 0.1062                | 0.5667             | 0.1624            |\n",
    "| 6/12          | [31, 30, 15, 2]   | 50          | 0.03         | 0.5472            | 0.5249         | 0.5553      | 0.5352     | 0.3492                   | 0.0993                | 0.5674             | 0.1546            |\n",
    "| 7/12          | [31, 30, 15, 2]   | 100         | 0.01         | 0.5380            | 0.6288         | 0.5557      | 0.5785     | 0.3441                   | 0.1415                | 0.5689             | 0.2005            |\n",
    "| 8/12          | [31, 30, 15, 2]   | 100         | 0.03         | 0.5371            | 0.6290         | 0.5545      | 0.5778     | 0.3376                   | 0.1504                | 0.5667             | 0.2081            |\n",
    "| 9/12          | [31, 40, 20, 2]   | 50          | 0.01         | 0.6092            | 0.5259         | 0.6376      | 0.5644     | 0.6930                   | 0.1641                | 0.6375             | 0.2651            |\n",
    "| 10/12         | [31, 40, 20, 2]   | 50          | 0.03         | 0.6048            | 0.5511         | 0.6379      | 0.5766     | 0.6829                   | 0.1959                | 0.6377             | 0.3039            |\n",
    "| 11/12         | [31, 40, 20, 2]   | 100         | 0.01         | 0.5859            | 0.6498         | 0.6407      | 0.6155     | 0.6709                   | 0.2923                | 0.6410             | 0.4032            |\n",
    "| 12/12         | [31, 40, 20, 2]   | 100         | 0.03         | 0.6083            | 0.5437         | 0.6374      | 0.5741     | 0.7053                   | 0.1836                | 0.6415             | 0.2913            |\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Random Forest**\n",
    "| **Param Set** | **numTrees** | **maxDepth** | **Avg Precision** | **Avg Recall** | **Avg AUC** | **Avg F1** | **Calibrated Precision** | **Calibrated Recall** | **Calibrated AUC** | **Calibrated F1** |\n",
    "|---------------|--------------|---------------|-------------------|----------------|-------------|------------|---------------------------|------------------------|---------------------|--------------------|\n",
    "| 1/9           | 10           | 5             | 0.5910            | 0.6287         | 0.6414      | 0.6091     | 0.7560                   | 0.0793                | 0.6414             | 0.1435            |\n",
    "| 2/9           | 10           | 8             | 0.6020            | 0.6176         | 0.6501      | 0.6089     | 0.7248                   | 0.1561                | 0.6501             | 0.2567            |\n",
    "| 3/9           | 10           | 12            | 0.6054            | 0.6300         | 0.6564      | 0.6156     | 0.7141                   | 0.1943                | 0.6564             | 0.3048            |\n",
    "| 4/9           | 15           | 5             | 0.5850            | 0.6590         | 0.6416      | 0.6191     | 0.7545                   | 0.0699                | 0.6416             | 0.1279            |\n",
    "| 5/9           | 15           | 8             | 0.5934            | 0.6641         | 0.6533      | 0.6238     | 0.7466                   | 0.1225                | 0.6533             | 0.2100            |\n",
    "| **6/9**       | **15**       | **12**        | **0.5979**        | **0.6669**     | **0.6563**  | **0.6243** | **0.7022**               | **0.2429**            | **0.6563**         | **0.3572**        |\n",
    "| 7/9           | 20           | 5             | 0.5906            | 0.6249         | 0.6438      | 0.6071     | 0.7558                   | 0.0805                | 0.6438             | 0.1453            |\n",
    "| 8/9           | 20           | 8             | 0.6015            | 0.6356         | 0.6551      | 0.6163     | 0.7297                   | 0.1684                | 0.6551             | 0.2735            |\n",
    "| 9/9           | 20           | 12            | 0.6072            | 0.6390         | **0.6623**  | 0.6207     | 0.7245                   | 0.2121                | **0.6623**         | 0.3282            |\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a55ee7b0-b6e2-416f-85ad-9d70143505ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Results and Discussion\n",
    "### Model Evaluation\n",
    "After defining a simple baseline, we leveraged our full machine‑learning pipeline to train more sophisticated models available in Apache Spark's Machine Learning libray (MLlib). The following table summarizes their predictive accuracy and related metrics on the test dataset for flagging flights delayed by 15 minutes or more.\n",
    "\n",
    "| Model                | Precision | Recall  | AUC    | F1    | Notes                                      |\n",
    "|----------------------|-----------|---------|--------|-------|--------------------------------------------|\n",
    "| Absolute Baseline    | 0.2       | 0.2     | 0.5    | 0.2   |                                            |\n",
    "| MLP Single-Layer     | 0.3266    | 0.2879  | 0.6386 | 0.306 | layers=[31, 10, 2], maxIter=100, stepSize=0.01 |\n",
    "| MLP Dual-Layer       | 0.3489    | 0.233   | 0.642  | 0.2794| layers=[31, 30, 15, 2], maxIter=100, stepSize=0.01 |\n",
    "| Logistic Regression  | 0.6132    | 0.1676  | 0.7171 | 0.2632|                                            |\n",
    "| Random Forest        | 0.4545    | 0.097   | 0.6485 | 0.1599| best_numTrees: 20, best_maxDepth: 12       |\n",
    "\n",
    "### Results Discussion\n",
    "The absolute baseline model which predicted delays purely by historical delay ratios yielded a Precision, Recall, and F1 of 0.2, with an AUC of 0.5. This performance mirrors random guessing, confirming the need for more sophisticated techniques to capture complex patterns in the data.\n",
    "\n",
    "The Logistic Regression model achieves the highest Precision (0.6132), indicating it makes few false‑positive predictions. However, its Recall (0.1676) is notably low, meaning it misses the majority of delayed flights. Considering the project goal of maximizing Recall, its performance is lacking.\n",
    "\n",
    "Conversely, the MLP Single‑Layer model balances Precision (0.3266) and Recall (0.2879) to deliver the highest F1 score (0.306), making it more effective at detecting true delays while keeping false alarms within acceptable bounds.\n",
    "\n",
    "The MLP Dual‑Layer model slightly improves AUC (0.642) over the Single‑Layer version (0.6386) but sacrifices Recall (down to 0.233) and overall F1 score (0.2794). This suggests additional hidden layers may introduce overfitting or hamper the model’s ability to generalize delay patterns.\n",
    "\n",
    "Random Forest, despite its nonlinear capabilities, underperforms across most metrics (F1 of 0.1599 and Recall of 0.097), perhaps due to insufficient tree complexity or the need for further feature engineering to leverage its ensemble strength.\n",
    "\n",
    "### Model Selection\n",
    "Evaluation across models highlights the Single‑Layer MLP as the strongest performer. It records the highest Recall of 0.2879 and an F1 score of 0.306, demonstrating its effectiveness in correctly identifying positive instances without inflating false alarms. Its Precision of 0.3266 and AUC of 0.6386 further reinforce the model’s balanced performance, optimizing both sensitivity and specificity. Given these metrics, the Single‑Layer MLP offers the most dependable solution for maximizing true positive detection in our dataset.\n",
    "\n",
    "### Important Features\n",
    "Based on a weight analysis of the neurons in the hidden layer for the single-layer MLP model, the top 10 features are:\n",
    "1. **HourlyAltimeterSetting**: Score: 10.9176\n",
    "2. **CRS_DEP_TIME**: Score: 10.4867\n",
    "3. **HourlyRelativeHumidity**: Score: 8.8356\n",
    "4. **origin_airport_lon**: Score: 8.5671\n",
    "5. **CRS_ARR_TIME**: Score: 7.1204\n",
    "6. **origin_airport_lat**: Score: 6.8495\n",
    "7. **HourlyDewPointTemperature**: Score: 6.8400\n",
    "8. **MONTH_index**: Score: 6.7503\n",
    "9. **rolling_3mo_delay_count**: Score: 6.7112\n",
    "10. **OP_UNIQUE_CARRIER_index**: Score: 5.9972\n",
    "\n",
    "The Single‑Layer MLP’s top features—such as `HourlyAltimeterSetting`, `CRS_DEP_TIME`, and `HourlyRelativeHumidity` underscore the significance of both meteorological factors and scheduled times when predicting flight delays. These predictors align expectations as pressure settings and humidity influence flight safety procedures as weather can be very disruptive, while departure and arrival schedules reflect airline operations: later departures often coincide with deteriorating weather, elevating the risk of delays.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdd9e597-5dd8-4a86-b4d2-e48954d8bce9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "### Project Overview\n",
    "This project aimed to develop and evaluate machine‑learning models that predict whether a flight will be delayed by 15 minutes or more, empowering passengers to plan their travel and enhancing operational efficiency across the commercial airline industry. We hypothesized that integrating bespoke feature engineering into our machine‑learning pipeline yields more precise flight‑delay predictions than a naive benchmark that forecasts delays according to the observed distribution of past delays and on‑time arrivals. Furthermore, we anticipated that systematic hyperparameter optimization will deliver significant gains in model performance.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To achieve this, we extracted and ranked feature importance scores—leveraging contextual knowledge and correlation matrices to identify the strongest predictors—then built a unified pipeline that handled indexing, vector assembly, and feature scaling. We conducted a grid search to tune hyperparameters for optimal performance, and implemented a calibration step to balance evaluation metrics and mitigate bias introduced by down‑sampling. We also prioritized recall as our top-line metric in an effort to minimize false negatives, when flights were delayed but the model predicted they were not. This case is the most vital to prevent as it would foster a sense of distrust in our customer base if we fail to accurately identify delayed flights.\n",
    "\n",
    "\n",
    "### Final Model\n",
    "- **Best Model**: The MLP Single-Layer model was selected as the best model due to its high recall.\n",
    "- **Performance Metrics**:\n",
    "  - Precision=0.3266\n",
    "  - Recall=0.2879\n",
    "  - AUC=0.6386\n",
    "  - F1=0.3060\n",
    "- **Number of Features**: 31 Features (MinMaxScaled)\n",
    "- **Hyper-parameters**: The best hyper-parameters for the MLP Single-Layer model were:\n",
    "  - Layers: [31, 10, 2]\n",
    "  - Max Iterations: 100\n",
    "  - Step Size: 0.01\n",
    "- **Most Important Features**: Based on a weight analysis of the neurons in the hidden layer, the top 10 features are:\n",
    "  1. **HourlyAltimeterSetting**: Score: 10.9176\n",
    "  2. **CRS_DEP_TIME**: Score: 10.4867\n",
    "  3. **HourlyRelativeHumidity**: Score: 8.8356\n",
    "  4. **origin_airport_lon**: Score: 8.5671\n",
    "  5. **CRS_ARR_TIME**: Score: 7.1204\n",
    "  6. **origin_airport_lat**: Score: 6.8495\n",
    "  7. **HourlyDewPointTemperature**: Score: 6.8400\n",
    "  8. **MONTH_index**: Score: 6.7503\n",
    "  9. **rolling_3mo_delay_count**: Score: 6.7112\n",
    "  10. **OP_UNIQUE_CARRIER_index**: Score: 5.9972\n",
    "\n",
    "### Significance of Results\n",
    "The MLP Single-Layer model demonstrated a high recall, which is crucial for applications where identifying true positives is more important than minimizing false positives. This indicates that the model is effective in capturing the relevant patterns in the data and can be relied upon for making accurate predictions.\n",
    "\n",
    "### GAP analysis:\n",
    "The current best-performing pipeline—a calibrated single-layer MLP—demonstrates strong precision but low recall, falling short of a practical and reliable recall(at least 80%). This suggests the model is too conservative in identifying positive cases, potentially missing many true positives. To address this, we are exploring deeper neural network architectures to better capture complex patterns, as well as engineering more predictive features, including temporal and interaction-based variables. Future work could involve: implementing **decision trees** for interpretability and inherent feature selection; integrating **ensemble approaches** like boosting or stacking to improve predictive power; continuing **hyperparameter tuning** (e.g., tree depth, MLP architecture); adding **new features** to enrich the signal; evaluating **advanced models** for better generalization; and conducting **real-world validation** to ensure reliability and effectiveness in practical use. By iteratively refining and validating the pipeline, we aim to build a more accurate, robust model suited for deployment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9a322f0-f255-42dd-b9b2-00bfb36e4653",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Link to Code Notebook for Phase 3\n",
    "<a href=\"https://github.com/cweiss10/261_images/blob/main/Phase%203%20-%20Final%20-%20Team-1-3.html\" download>Download link</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Phase 3 - Final Report- Team-1-3",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}